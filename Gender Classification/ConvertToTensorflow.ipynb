{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "#A method to convert keras to tensorflow\n",
    "def keras_to_tf(keras_model, output_dir, model_name, out_prefix = \"output_\", log_tensorboard=True):\n",
    "    if os.path.exists(output_dir) == False:\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    out_nodes = []\n",
    "\n",
    "    for i in range(len(keras_model.outputs)):\n",
    "        out_nodes.append(out_prefix + str(i + 1))\n",
    "        tf.identity(keras_model.output[i], out_prefix + str(i + 1))\n",
    "\n",
    "    sess = K.get_session()\n",
    "    \n",
    "    from tensorflow.python.framework import graph_util, graph_io\n",
    "\n",
    "    init_graph = sess.graph.as_graph_def()\n",
    "\n",
    "    main_graph = graph_util.convert_variables_to_constants(sess, init_graph, out_nodes)\n",
    "\n",
    "    graph_io.write_graph(main_graph, output_dir, name=model_name, as_text=False)\n",
    "\n",
    "    if log_tensorboard:\n",
    "        from tensorflow.python.tools import import_pb_to_tensorboard\n",
    "\n",
    "        import_pb_to_tensorboard.import_to_tensorboard(\n",
    "            os.path.join(output_dir, model_name), output_dir)\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    We explicitly redefine the Squeezent architecture since Keras has no predefined Squeezenet\n",
    "    \"\"\"\n",
    "def squeezenet_fire_module(inputs, input_channel_small=16, input_channel_large=64):\n",
    "\n",
    "    channel_axis = 3\n",
    "\n",
    "    inputs = Conv2D(input_channel_small, (1,1), padding=\"valid\" )(inputs)\n",
    "    inputs = Activation(\"relu\")(inputs)\n",
    "\n",
    "    input_branch_1 = Conv2D(input_channel_large, (1,1), padding=\"valid\" )(inputs)\n",
    "    input_branch_1 = Activation(\"relu\")(input_branch_1)\n",
    "\n",
    "    input_branch_2 = Conv2D(input_channel_large, (3, 3), padding=\"same\")(inputs)\n",
    "    input_branch_2 = Activation(\"relu\")(input_branch_2)\n",
    "\n",
    "    inputs = concatenate([input_branch_1, input_branch_2], axis=channel_axis)\n",
    "\n",
    "    return inputs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def SqueezeNet(input_shape=(128,128,3)):\n",
    "\n",
    "\n",
    "\n",
    "    image_input = Input(shape=input_shape)\n",
    "\n",
    "\n",
    "    network = Conv2D(64, (3,3), strides=(2,2), padding=\"valid\")(image_input)\n",
    "    network = Activation(\"relu\")(network)\n",
    "    network = MaxPool2D( pool_size=(3,3) , strides=(2,2))(network)\n",
    "\n",
    "    network = squeezenet_fire_module(inputs=network, input_channel_small=16, input_channel_large=32)\n",
    "    network = squeezenet_fire_module(inputs=network, input_channel_small=16, input_channel_large=32)\n",
    "    network = MaxPool2D(pool_size=(3,3), strides=(2,2))(network)\n",
    "\n",
    "    #network = squeezenet_fire_module(inputs=network, input_channel_small=32, input_channel_large=128)\n",
    "    #network = squeezenet_fire_module(inputs=network, input_channel_small=32, input_channel_large=128)\n",
    "    network = MaxPool2D(pool_size=(3, 3), strides=(2, 2))(network)\n",
    "\n",
    "    #network = squeezenet_fire_module(inputs=network, input_channel_small=48, input_channel_large=192)\n",
    "    #network = squeezenet_fire_module(inputs=network, input_channel_small=48, input_channel_large=192)\n",
    "    #network = squeezenet_fire_module(inputs=network, input_channel_small=64, input_channel_large=256)\n",
    "    #network = squeezenet_fire_module(inputs=network, input_channel_small=64, input_channel_large=256)\n",
    "\n",
    "    #Remove layers like Dropout and BatchNormalization, they are only needed in training\n",
    "    #network = Dropout(0.5)(network)\n",
    "\n",
    "    network = Conv2D(1000, kernel_size=(1,1), padding=\"valid\", name=\"last_conv\")(network)\n",
    "    network = Activation(\"relu\")(network)\n",
    "\n",
    "    network = GlobalAvgPool2D()(network)\n",
    "    #network = Activation(\"softmax\",name=\"output\")(network)\n",
    "    \n",
    "    network = Flatten()(network)\n",
    "    network = Dense(units = 1, activation='sotfmax', )\n",
    "\n",
    "\n",
    "    input_image = image_input\n",
    "    model = Model(inputs=input_image, outputs=network)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = SqueezeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 4 layers into a model with 8 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-c737c2646c4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkeras_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model1.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"checkpoint\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mkeras_to_tf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"squeezenet.pb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep_Learning\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep_Learning\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1228\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[1;32m-> 1230\u001b[1;33m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[0;32m   1231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'close'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep_Learning\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers, reshape)\u001b[0m\n\u001b[0;32m   1207\u001b[0m                          \u001b[1;34m'containing '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m                          \u001b[1;34m' layers into a model with '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1209\u001b[1;33m                          str(len(filtered_layers)) + ' layers.')\n\u001b[0m\u001b[0;32m   1210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m     \u001b[1;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to load a weight file containing 4 layers into a model with 8 layers."
     ]
    }
   ],
   "source": [
    "keras_model.load_weights(\"model1.h5\")\n",
    "\n",
    "output_dir = os.path.join(os.getcwd(),\"checkpoint\")\n",
    "keras_to_tf(keras_model, output_dir=output_dir, model_name=\"squeezenet.pb\")\n",
    "\n",
    "print(\"Model Saved!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "date = datetime.now()\n",
    "\n",
    "datenow = date.ctime()\n",
    "datenow[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jun  9 16:09:49 2020'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
